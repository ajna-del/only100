{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Babti",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajna-del/only100/blob/master/Babti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3awv16QmqJB",
        "colab_type": "code",
        "outputId": "28a2d361-9309-4555-93e0-b8259ba112c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        }
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#for timing\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "#for 100 images \n",
        "# download = drive.CreateFile({'id': '1PXrItwSZ3FP3dH5Lx-Zm2v4F42XtSJyY'})\n",
        "# download.GetContentFile('EyesOnly100.7z') # Save content of this file as a local file - images\n",
        "# os.mkdir('/content/RenamedImages')\n",
        "# !7z e EyesOnly100.7z -o'/content/RenamedImages'\n",
        "\n",
        "# for 1000 images\n",
        "# download = drive.CreateFile({'id': '13-mrV4pFxHxRRTM8LY_QVpkJhwMOEOoO'})\n",
        "# download.GetContentFile('EyesOnly1000.7z') # Save content of this file as a local file - images\n",
        "# os.mkdir('/content/RenamedImages')\n",
        "# !7z e EyesOnly1000.7z -o'/content/RenamedImages'\n",
        "\n",
        "# for 7000 images\n",
        "download = drive.CreateFile({'id': '1SzOJtqdPj9DOCIYv1Pp1E822-jiOcpXF'})\n",
        "download.GetContentFile('EyesAll7000.7z') # Save content of this file as a local file - images \n",
        "!7z e EyesAll7000.7z -o'/content/RenamedImages'\n",
        "\n",
        "#flipped images \n",
        "# download = drive.CreateFile({'id': '1BBWTD6IUToixY2w0a-nclhTKle1Lp5Oa'})\n",
        "# download.GetContentFile('RenamedImagesFlipped.7z') # Save content of this file as a local file - images\n",
        "# os.mkdir('/content/RenamedImages')\n",
        "# !7z e RenamedImagesFlipped.7z -o'/content/RenamedImages'\n",
        "\n",
        "#new labels 7000\n",
        "# download = drive.CreateFile({'id': '1f1WDP7DiUMaDBoPjOmqj2Q-dS6JxCQhJ'})\n",
        "# download.GetContentFile('NewLabels7000.7z') # Save content of this file as a local file - images\n",
        "# os.mkdir('/content/RenamedImages')\n",
        "# !7z e NewLabels7000.7z -o'/content/RenamedImages'\n",
        "\n",
        "#new labels - undersampled 2308 images\n",
        "# download = drive.CreateFile({'id': '1wYWfu9enq8IBRtBa1iuRtZlOsXZSXURV'})\n",
        "# download.GetContentFile('CorrectLabelsUndersampled.7z') # Save content of this file as a local file - images\n",
        "# os.mkdir('/content/RenamedImages')\n",
        "# !7z e CorrectLabelsUndersampled.7z -o'/content/RenamedImages'\n",
        "\n",
        "#G test...what is happening?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1832 sha256=1228a872ef4d9d239d7560921a0645a5c7f1e72e55233c216dbb736cbd709084\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,40 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1316909156 bytes (1256 MiB)\n",
            "\n",
            "Extracting archive: EyesAll7000.7z\n",
            "--\n",
            "Path = EyesAll7000.7z\n",
            "Type = 7z\n",
            "Physical Size = 1316909156\n",
            "Headers Size = 75359\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - A_102_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 22 - A_1154_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 46 - A_1458_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 61 - A_168_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 82 - A_1835_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 100 - A_1847_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 119 - A_1869_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% 138 - A_1884_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 154 - A_1919_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 171 - A_210_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 192 - A_266_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 217 - A_410_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 240 - A_532_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 264 - A_615_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 292 - A_847_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 313 - A_934_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 335 - C_1083_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 356 - C_1285_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 365 - C_1452_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 379 - C_1490_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 396 - C_2097_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 422 - C_2110_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 446 - C_2122_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 477 - C_2138_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 503 - C_2152_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 529 - C_2165_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 547 - C_2174_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 572 - C_2189_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 600 - C_2203_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 619 - C_2212_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 643 - C_2225_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 654 - C_2231_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 678 - C_2244_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 698 - C_330_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 722 - C_629_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 734 - C_81_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 760 - D_1071_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 772 - D_1094_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 793 - D_1153_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 808 - D_120_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 827 - D_1285_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 842 - D_139_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 861 - D_1474_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 882 - D_1657_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 901 - D_177_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 902 - D_1838_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 915 - D_195_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 938 - D_202_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 960 - D_209_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 980 - D_2161_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1004 - D_2228_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1031 - D_251_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1048 - D_27_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1068 - D_2_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1092 - D_338_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1113 - D_369_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1139 - D_3936_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1160 - D_3948_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1179 - D_3957_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1196 - D_3970_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1214 - D_3980_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1236 - D_3992_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1255 - D_4001_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1280 - D_4018_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1303 - D_4030_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1324 - D_4043_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1345 - D_4053_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1368 - D_4068_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1395 - D_4082_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1418 - D_4095_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1433 - D_4102_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1443 - D_4109_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1454 - D_4115_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1476 - D_4125_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1500 - D_4138_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1516 - D_4147_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1535 - D_4158_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1557 - D_4169_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1576 - D_4180_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1599 - D_4193_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1622 - D_4204_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1645 - D_4214_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1661 - D_4223_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1668 - D_4227_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1672 - D_422_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1694 - D_4240_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1710 - D_4248_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1723 - D_4254_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1743 - D_4266_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1766 - D_4278_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1789 - D_4288_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1810 - D_4299_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1829 - D_4308_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1851 - D_4318_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1871 - D_4327_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1890 - D_4337_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1911 - D_4348_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1933 - D_4359_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1951 - D_4368_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1972 - D_4380_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1987 - D_4388_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 2006 - D_4399_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 2024 - D_4409_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 2045 - D_441_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 2058 - D_4427_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 2065 - D_442_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 2087 - D_4441_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2103 - D_444_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2126 - D_4462_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2151 - D_4474_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2174 - D_4488_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2187 - D_4494_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 2207 - D_4504_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 2226 - D_4519_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 2241 - D_4527_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 2246 - D_452_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2265 - D_4539_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2289 - D_4551_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2314 - D_4567_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 2328 - D_4576_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2344 - D_4586_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2363 - D_4596_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2385 - D_4608_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2400 - D_4616_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 2415 - D_4623_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2423 - D_4627_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2447 - D_4639_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2471 - D_4657_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 2488 - D_4672_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 2516 - D_469_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 2535 - D_486_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 2555 - D_499_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 2583 - D_537_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2606 - D_551_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2626 - D_571_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2642 - D_594_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 2668 - D_616_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2692 - D_642_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2718 - D_669_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2739 - D_690_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2741 - D_691_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 2767 - D_713_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2789 - D_744_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2808 - D_757_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2833 - D_785_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 2853 - D_79_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 2882 - D_81_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 2900 - D_860_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 2917 - D_87_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 2938 - D_914_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 2955 - D_934_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 2974 - D_953_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 2996 - D_978_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 3013 - G_1210_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 3037 - G_1225_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 3058 - G_1239_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 3078 - G_1256_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 3100 - G_1268_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 3101 - G_1268_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 3119 - G_1280_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 3141 - G_1297_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 3161 - G_1325_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 3179 - G_1362_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3198 - G_1389_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3209 - G_1401_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3228 - G_1413_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3254 - G_1426_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 3275 - G_1441_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 3288 - G_1458_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 3303 - G_1473_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 3307 - G_1475_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 3324 - G_1487_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 3339 - G_1495_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 3356 - G_153_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 3385 - G_1975_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 3409 - G_2032_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 3423 - G_30_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 3444 - H_1046_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 3462 - H_1290_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 3482 - H_1867_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 3499 - H_23_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 3527 - H_3939_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 3551 - H_4090_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 3573 - H_4327_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3593 - H_4784_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3613 - H_723_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3631 - H_849_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3636 - H_95_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 3655 - M_1150_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 3674 - M_1366_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 3699 - M_1530_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 3712 - M_1537_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 3735 - M_1549_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3759 - M_1561_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3775 - M_1569_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3777 - M_1570_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3798 - M_1584_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 3818 - M_1597_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 3838 - M_1609_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 3863 - M_1621_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 3884 - M_1644_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 3907 - M_1674_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 3931 - M_174_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 3958 - M_475_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 3983 - M_771_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 4000 - N_1253_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 4021 - N_2336_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 4038 - N_2345_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 4053 - N_2352_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 4063 - N_2357_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 4091 - N_2371_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 4105 - N_2378_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 4122 - N_2387_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 4143 - N_2397_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 4168 - N_2410_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 4188 - N_2420_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 4212 - N_2432_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 4234 - N_2443_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 4251 - N_2451_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4274 - N_2463_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4291 - N_2471_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4310 - N_2481_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4319 - N_2485_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 4329 - N_2490_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 4349 - N_2500_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 4374 - N_2513_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 4396 - N_2524_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 4419 - N_2535_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 4447 - N_2549_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 4470 - N_2561_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 4489 - N_2570_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 4509 - N_2580_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 4536 - N_2594_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 4553 - N_2602_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 4563 - N_2607_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 4564 - N_2608_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4582 - N_2617_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4608 - N_2630_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4634 - N_2643_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4656 - N_2654_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 4674 - N_2663_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 4696 - N_2674_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 4712 - N_2682_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 4730 - N_2691_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 4743 - N_2697_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4749 - N_2700_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4775 - N_2713_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4790 - N_2721_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4806 - N_2729_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 4824 - N_2738_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 4849 - N_2750_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 4871 - N_2761_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 4886 - N_2769_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 4890 - N_2771_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4912 - N_2782_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4937 - N_2794_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4964 - N_2808_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4965 - N_2808_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 4984 - N_2818_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 5010 - N_2831_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 5036 - N_2844_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 5058 - N_2855_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 5087 - N_2869_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 5088 - N_2870_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 5117 - N_2884_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 5141 - N_2896_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 5160 - N_2906_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 5182 - N_2917_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5204 - N_2928_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5225 - N_2938_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5246 - N_2949_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5267 - N_2959_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 5279 - N_2965_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 5296 - N_2974_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 5315 - N_2983_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 5332 - N_2992_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 5333 - N_2992_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5352 - N_3002_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5378 - N_3015_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5400 - N_3026_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5401 - N_3026_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 5413 - N_3032_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 5425 - N_3038_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 5441 - N_3046_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 5459 - N_3055_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 5480 - N_3066_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5501 - N_3076_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5520 - N_3086_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5536 - N_3094_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5554 - N_3103_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 5568 - N_3110_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5574 - N_3113_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5585 - N_3118_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5603 - N_3127_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5626 - N_3139_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 5640 - N_3146_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5645 - N_3148_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5663 - N_3157_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5688 - N_3170_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5709 - N_3180_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 5736 - N_3194_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 5737 - N_3194_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 5758 - N_3205_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 5781 - N_3216_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 5798 - N_3225_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 5814 - N_3233_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 5836 - N_3244_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 5855 - N_3253_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 5876 - N_3264_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 5877 - N_3264_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5896 - N_3274_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5921 - N_3286_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5943 - N_3297_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5967 - N_3309_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 5970 - N_3311_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 5993 - N_3322_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 6016 - N_3334_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 6041 - N_3346_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 6059 - N_3355_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 6079 - N_3365_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 6080 - N_3366_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 6096 - N_3374_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 6118 - N_3385_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 6140 - N_3396_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6162 - N_3407_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6177 - N_3414_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6197 - N_3424_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6218 - N_3435_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 6225 - N_3438_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6248 - N_394_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6267 - N_8_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6285 - O_1012_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6313 - O_1032_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 6320 - O_1039_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6335 - O_1056_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6362 - O_108_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6381 - O_10_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6399 - O_1120_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 6419 - O_1133_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 6424 - O_113_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 6442 - O_1156_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 6461 - O_1171_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 6481 - O_1198_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 6495 - O_1214_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6509 - O_1240_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6535 - O_1296_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6554 - O_1311_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6555 - O_1311_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 6577 - O_138_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6599 - O_1422_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6615 - O_146_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6616 - O_1471_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6635 - O_151_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6644 - O_1557_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 6667 - O_1585_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6671 - O_1595_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6692 - O_163_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6714 - O_1673_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6733 - O_1718_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 6736 - O_172_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6750 - O_1801_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6771 - O_186_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6792 - O_194_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6793 - O_194_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 6805 - O_1970_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6829 - O_200_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6848 - O_2053_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6849 - O_2053_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6865 - O_20_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 6891 - O_2173_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6915 - O_222_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6916 - O_224_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6939 - O_240_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6961 - O_254_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6973 - O_25_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 6978 - O_263_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 6996 - O_276_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 7024 - O_290_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 7043 - O_301_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 7044 - O_302_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 7059 - O_30_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7071 - O_317_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7099 - O_335_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7105 - O_338_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7119 - O_344_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 7138 - O_357_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7160 - O_36_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7161 - O_36_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7185 - O_384_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7204 - O_395_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7222 - O_404_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 7227 - O_405_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7255 - O_421_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7275 - O_430_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7280 - O_433_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7289 - O_4366_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7311 - O_446_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 7329 - O_454_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 7329 - O_454_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 7346 - O_460_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 7365 - O_470_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 7386 - O_483_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 7395 - O_488_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7409 - O_497_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7431 - O_509_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7450 - O_51_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7471 - O_52_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 7472 - O_531_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 7494 - O_548_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 7518 - O_573_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 7536 - O_584_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 7540 - O_586_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 7550 - O_590_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7569 - O_601_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7591 - O_61_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7593 - O_620_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7613 - O_630_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 7632 - O_640_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7647 - O_647_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7655 - O_650_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7681 - O_666_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7704 - O_680_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 7716 - O_689_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7724 - O_693_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7749 - O_705_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7774 - O_721_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7775 - O_721_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7793 - O_732_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 7814 - O_745_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7827 - O_752_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7838 - O_760_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7860 - O_774_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7885 - O_791_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 7892 - O_796_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7905 - O_800_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7926 - O_816_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7950 - O_833_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7951 - O_833_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7968 - O_841_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 7985 - O_850_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 7997 - O_858_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 8004 - O_863_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 8025 - O_876_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 8045 - O_887_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 8053 - O_892_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8066 - O_899_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8086 - O_909_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8103 - O_919_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8107 - O_920_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8128 - O_932_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 8138 - O_940_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8161 - O_953_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8162 - O_954_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8181 - O_969_right.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8206 - O_986_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8212 - O_98_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 8218 - O_993_left.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 8230\n",
            "Size:       1668212065\n",
            "Compressed: 1316909156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHuJkam1R3VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from PIL import Image\n",
        "# from PIL import ImageOps\n",
        "# folder = os.listdir('/content/RenamedImages')\n",
        "# keyword = 'right'\n",
        "\n",
        "# for filename in folder:\n",
        "#   if keyword in filename:\n",
        "#     im = Image.open(os.path.join('/content/RenamedImages', filename))\n",
        "#     im = ImageOps.mirror(im) # is it being saved?\n",
        "#     im.save(os.path.join('/content/RenamedImages', filename))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWYBYodhq9UR",
        "colab_type": "code",
        "outputId": "d6646dc3-7427-4dfa-f3d4-a7d1806046e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.mkdir('/content/RenamedImages/ClassN') \n",
        "os.mkdir('/content/RenamedImages/ClassO')\n",
        "os.mkdir('/content/RenamedImages/ClassC') \n",
        "os.mkdir('/content/RenamedImages/ClassA') \n",
        "os.mkdir('/content/RenamedImages/ClassH') \n",
        "os.mkdir('/content/RenamedImages/ClassM')\n",
        "os.mkdir('/content/RenamedImages/ClassD') \n",
        "os.mkdir('/content/RenamedImages/ClassG')\n",
        "for filename in os.listdir('/content/RenamedImages'): # files extracted from zip file\n",
        "  directory = '/content/RenamedImages'\n",
        "  directoryN = '/content/RenamedImages/ClassN'\n",
        "  directoryO = '/content/RenamedImages/ClassO'\n",
        "  directoryC = '/content/RenamedImages/ClassC'\n",
        "  directoryA = '/content/RenamedImages/ClassA'\n",
        "  directoryH = '/content/RenamedImages/ClassH'\n",
        "  directoryM = '/content/RenamedImages/ClassM'\n",
        "  directoryD = '/content/RenamedImages/ClassD'\n",
        "  directoryG = '/content/RenamedImages/ClassG'\n",
        "  if filename.endswith('jpg'):\n",
        "    if filename.startswith('N'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryN,filename))\n",
        "    elif filename.startswith('O'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryO,filename))\n",
        "    elif filename.startswith('C'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryC,filename))\n",
        "    elif filename.startswith('A'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryA,filename))\n",
        "    elif filename.startswith('H'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryH,filename))\n",
        "    elif filename.startswith('M'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryM,filename))\n",
        "    elif filename.startswith('D'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryD,filename))\n",
        "    elif filename.startswith('G'):\n",
        "      os.rename(os.path.join(directory,filename), os.path.join(directoryG,filename))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 233 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgi0PvEmufVe",
        "colab_type": "code",
        "outputId": "90cbbfd6-f37b-46f1-faa0-97c368e15639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!pip install split-folders tqdm\n",
        "import split_folders\n",
        "split_folders.ratio('/content/RenamedImages', output=\"output\", seed=333, ratio=(.8, .1, .1)) # default values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 8230 files [00:05, 1507.41 files/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 8.49 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wj9uPjntpmt",
        "colab_type": "code",
        "outputId": "88dd99c4-7c24-4887-bed1-33678eade494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# folder = os.listdir('/content/output/test/')\n",
        "# folder1 = os.listdir('/content/output/train/ClassN') #2\n",
        "# folder2 = os.listdir('/content/output/train/ClassP') #22\n",
        "# print(folder)\n",
        "# print(folder1)\n",
        "# print(folder2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 916 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K6xkqZzy9OZ",
        "colab_type": "code",
        "outputId": "ba3cbf6f-f961-4ddb-b252-5d9515c0c1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.multiprocessing\n",
        "# from torch.nn.utils.rnn import pack_sequence\n",
        "# from torch.nn.utils.rnn import pack_padded_sequence\n",
        "torch.multiprocessing.set_sharing_strategy('file_system') # try with more num_workers\n",
        "\n",
        "def pad_sequence(sequences, batch_first=False, padding_value=0):\n",
        "  max_size = sequences[0].size()\n",
        "  # print('max_size',max_size)\n",
        "  trailing_dims = max_size[1:] #other dimensions\n",
        "  # print(max_size[1:])\n",
        "  max_len = max([s.size(0) for s in sequences])\n",
        "  # print('max_len',max_len)\n",
        "  max_other_len = max([s.size(1) for s in sequences])\n",
        "  max_more_len = max([s.size(2) for s in sequences])\n",
        "  if batch_first:\n",
        "      out_dims = (len(sequences), max_len,max_other_len,max_more_len)\n",
        "      # print('out_dims',out_dims)\n",
        "  else:\n",
        "      out_dims = (max_len, len(sequences)) + trailing_dims\n",
        "\n",
        "  out_tensor = sequences[0].data.new(*out_dims).fill_(padding_value)\n",
        "  for i, tensor in enumerate(sequences):\n",
        "      length = tensor.size(0)\n",
        "      # print('length', length)\n",
        "      width = tensor.size(1)\n",
        "      # print('width', width)\n",
        "      height = tensor.size(2)\n",
        "      # print('height ',height)\n",
        "      # use index notation to prevent duplicate references to the tensor\n",
        "      if batch_first:\n",
        "          out_tensor[i, :length, :width ,:height] = tensor\n",
        "      else:\n",
        "          out_tensor[ :length, :width,:height,i] = tensor\n",
        "\n",
        "  return out_tensor\n",
        "\n",
        "#collate function\n",
        "def my_collate(batch):\n",
        "    # batch contains a list of tuples of structure (sequence, target)\n",
        "    targets = [item[1]  for item in batch] # list of labels\n",
        "    data = [item[0] for item in batch]\n",
        "    data = pad_sequence(data, batch_first=True)          \n",
        "    targets = torch.FloatTensor(targets)\n",
        "    targets = targets.type(torch.LongTensor)\n",
        "    print(data.size())\n",
        "    # print(targets)\n",
        "    return [data, targets]\n",
        "\n",
        "\n",
        "transform2 = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "# transform1 = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomGrayscale(),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) \n",
        "# transform1 = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomGrayscale(),transforms.ToTensor()]) #without normalization\n",
        "transform1 = transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomGrayscale(),transforms.Resize((200,200)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) \n",
        "\n",
        "#training\n",
        "trainset = torchvision.datasets.ImageFolder(root='/content/output/train', transform = transform1, target_transform=None) #transform here can crop image\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4,shuffle = True, num_workers = 0, collate_fn=my_collate,pin_memory=True)\n",
        "#testing\n",
        "testset = torchvision.datasets.ImageFolder(root='/content/output/test', transform = transform2, target_transform=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size =4,shuffle = True, num_workers = 0,collate_fn=my_collate,pin_memory=True) \n",
        "#validation\n",
        "valset = torchvision.datasets.ImageFolder(root='/content/output/val', transform = transform2, target_transform=None)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size = 4,shuffle = True, num_workers = 0,collate_fn=my_collate,pin_memory=True)\n",
        "classes = ('N','D','G','C','A','H','M','O')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.45 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MM_q6rf2U3l",
        "colab_type": "code",
        "outputId": "e5d5478b-0edc-4602-abeb-c29bbed6a6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# # print(trainset)\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# dataiter = iter(trainloader)\n",
        "# images, labels = dataiter.next()\n",
        "# print(type(images))\n",
        "# print(images.shape) #torch.Size([4, 3, 1984, 2976])\n",
        "#                     # returns 4 images, with 3 channels(RGB) and their dimensions\n",
        "# images = images[2].reshape(3, 1984,-1)\n",
        "# print(labels[2]) # vector with 4 elements\n",
        "# plt.imshow(images[0].numpy().squeeze(), cmap = 'Greys_r');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 613 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRqgk-r0Ek4C",
        "colab_type": "code",
        "outputId": "af4228f5-ea82-45be-9789-1297496f3511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class PyramidPooling(nn.Module):\n",
        "    def __init__(self, levels, mode=\"max\"):\n",
        "        \"\"\"\n",
        "        General Pyramid Pooling class which uses Spatial Pyramid Pooling by default and holds the static methods for both spatial and temporal pooling.\n",
        "        :param levels defines the different divisions to be made in the width and (spatial) height dimension\n",
        "        :param mode defines the underlying pooling mode to be used, can either be \"max\" or \"avg\"\n",
        "        :returns a tensor vector with shape [batch x 1 x n], where  n: sum(filter_amount*level*level) for each level in levels (spatial) or\n",
        "                                                                    n: sum(filter_amount*level) for each level in levels (temporal)\n",
        "                                            which is the concentration of multi-level pooling\n",
        "        \"\"\"\n",
        "        super(PyramidPooling, self).__init__()\n",
        "        self.levels = levels\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.spatial_pyramid_pool(x, self.levels, self.mode)\n",
        "\n",
        "    def get_output_size(self, filters):\n",
        "        out = 0\n",
        "        for level in self.levels:\n",
        "            out += filters * level * level\n",
        "        return out\n",
        "class SpatialPyramidPooling(PyramidPooling):\n",
        "    def __init__(self, levels, mode=\"max\"):\n",
        "        \"\"\"\n",
        "                Spatial Pyramid Pooling Module, which divides the input Tensor horizontally and horizontally\n",
        "                (last 2 dimensions) according to each level in the given levels and pools its value according to the given mode.\n",
        "                Can be used as every other pytorch Module and has no learnable parameters since it's a static pooling.\n",
        "                In other words: It divides the Input Tensor in level*level rectangles width of roughly (previous_conv.size(3) / level)\n",
        "                and height of roughly (previous_conv.size(2) / level) and pools its value. (pads input to fit)\n",
        "                :param levels defines the different divisions to be made in the width dimension\n",
        "                :param mode defines the underlying pooling mode to be used, can either be \"max\" or \"avg\"\n",
        "                :returns (forward) a tensor vector with shape [batch x 1 x n],\n",
        "                                                    where n: sum(filter_amount*level*level) for each level in levels\n",
        "                                                    which is the concentration of multi-level pooling\n",
        "                \"\"\"\n",
        "        super(SpatialPyramidPooling, self).__init__(levels, mode=mode)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.spatial_pyramid_pool(x, self.levels, self.mode)\n",
        "\n",
        "    def get_output_size(self, filters):\n",
        "        \"\"\"\n",
        "                Calculates the output shape given a filter_amount: sum(filter_amount*level*level) for each level in levels\n",
        "                Can be used to x.view(-1, spp.get_output_size(filter_amount)) for the fully-connected layers\n",
        "                :param filters: the amount of filter of output fed into the spatial pyramid pooling\n",
        "                :return: sum(filter_amount*level*level)\n",
        "        \"\"\"\n",
        "        out = 0\n",
        "        for level in self.levels:\n",
        "            out += filters * level * level\n",
        "        return out\n",
        "def spatial_pyramid_pool(previous_conv, levels, mode):\n",
        "        \"\"\"\n",
        "        Static Spatial Pyramid Pooling method, which divides the input Tensor vertically and horizontally\n",
        "        (last 2 dimensions) according to each level in the given levels and pools its value according to the given mode.\n",
        "        :param previous_conv input tensor of the previous convolutional layer\n",
        "        :param levels defines the different divisions to be made in the width and height dimension\n",
        "        :param mode defines the underlying pooling mode to be used, can either be \"max\" or \"avg\"\n",
        "        :returns a tensor vector with shape [batch x 1 x n],\n",
        "                                            where n: sum(filter_amount*level*level) for each level in levels\n",
        "                                            which is the concentration of multi-level pooling\n",
        "        \"\"\"\n",
        "        num_sample = previous_conv.size(0)\n",
        "        previous_conv_size = [int(previous_conv.size(2)), int(previous_conv.size(3))]\n",
        "        for i in range(len(levels)):\n",
        "            h_kernel = int(math.ceil(previous_conv_size[0] / levels[i]))\n",
        "            w_kernel = int(math.ceil(previous_conv_size[1] / levels[i]))\n",
        "            w_pad1 = int(math.floor((w_kernel * levels[i] - previous_conv_size[1]) / 2))\n",
        "            w_pad2 = int(math.ceil((w_kernel * levels[i] - previous_conv_size[1]) / 2))\n",
        "            h_pad1 = int(math.floor((h_kernel * levels[i] - previous_conv_size[0]) / 2))\n",
        "            h_pad2 = int(math.ceil((h_kernel * levels[i] - previous_conv_size[0]) / 2))\n",
        "            assert w_pad1 + w_pad2 == (w_kernel * levels[i] - previous_conv_size[1]) and \\\n",
        "                   h_pad1 + h_pad2 == (h_kernel * levels[i] - previous_conv_size[0])\n",
        "\n",
        "            padded_input = F.pad(input=previous_conv, pad=[w_pad1, w_pad2, h_pad1, h_pad2],\n",
        "                                 mode='constant', value=0)\n",
        "            if mode == \"max\":\n",
        "                pool = nn.MaxPool2d((h_kernel, w_kernel), stride=(h_kernel, w_kernel), padding=(0, 0))\n",
        "            elif mode == \"avg\":\n",
        "                pool = nn.AvgPool2d((h_kernel, w_kernel), stride=(h_kernel, w_kernel), padding=(0, 0))\n",
        "            else:\n",
        "                raise RuntimeError(\"Unknown pooling type: %s, please use \\\"max\\\" or \\\"avg\\\".\")\n",
        "            x = pool(padded_input)\n",
        "            if i == 0:\n",
        "                spp = x.view(num_sample, -1)\n",
        "            else:\n",
        "                spp = torch.cat((spp, x.view(num_sample, -1)), 1)\n",
        "\n",
        "        return spp\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 55 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EymDIUSD4UrP",
        "colab_type": "code",
        "outputId": "7aed9119-301a-4823-86b5-4f2f1238cca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# #defining convolution neural network\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "        \n",
        "#         self.conv1 = nn.Conv2d(3,6,3) #in_channels, out_channels, kernel_size\n",
        "#         # nn.init.xavier_uniform_(self.conv1.weight)\n",
        "#         # nn.init.zeros_(self.conv1.bias)\n",
        "#         self.pool = nn.MaxPool2d(5, stride=3) #kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False\n",
        "#         self.conv2 = nn.Conv2d(6,16,3)\n",
        "#         # nn.init.xavier_uniform_(self.conv2.weight)\n",
        "#         # nn.init.zeros_(self.conv2.bias)\n",
        "#         self.fc1 = nn.Linear(288,80)\n",
        "#         self.fc2 = nn.Linear(80, 48)\n",
        "#         self.fc3 = nn.Linear(48 ,8) \n",
        "#         self.dropout = nn.Dropout(0.5) \n",
        "#         # self.batchnorm = nn.BatchNorm2d(3)\n",
        "       \n",
        "#     def forward(self,x):\n",
        "#         # x = self.batchnorm(x)\n",
        "#         x = self.pool(F.relu(self.conv1(x)))\n",
        "#         print(x.size())\n",
        "#         x = F.relu(self.conv2(x))\n",
        "#         # print(x.size())\n",
        "#         x = spatial_pyramid_pool(x,(3,3),'max') \n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         # print(x.size())\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         # print(x.size())\n",
        "#         x = self.fc3(x)\n",
        "#         # print(x.size())\n",
        "#         return x\n",
        "# net = Net()\n",
        "\n",
        "# defining convolution neural network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()      \n",
        "        self.conv1 = nn.Conv2d(3,6,3) #in_channels, out_channels, kernel_size\n",
        "        self.pool = nn.MaxPool2d(5, stride=3) #kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.fc1 = nn.Linear(614656 ,996)\n",
        "        self.fc2 = nn.Linear(996, 8) \n",
        "        self.m = nn.LeakyReLU()\n",
        "       \n",
        "    def forward(self,x):\n",
        "        x = self.m(self.conv1(x))\n",
        "        # print(x.size())\n",
        "        x = self.m(self.conv2(x))\n",
        "        print(x.size())\n",
        "        x = x.view(-1,16*196*196)\n",
        "        # print(x.size())\n",
        "        x = self.fc1(x)\n",
        "        # print(x.size())\n",
        "        x = self.fc2(x)\n",
        "        # print(x.size())\n",
        "        \n",
        "        # print(x.size())\n",
        "        return x\n",
        "net = Net()\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDJ6b8tr42tx",
        "colab_type": "code",
        "outputId": "0a3014f0-0e4f-495e-ecd5-f01d6b5b45cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#define loss function and optimizer\n",
        "#We're using Classification Cross-Entropy loss and SGD with momentum\n",
        "import torch.optim as optim\n",
        "# summed = 2993+1816+333+313+287+195+292+1263\n",
        "# weight = torch.tensor([2993,1816,333,313,287,195,292,1263])/summed\n",
        "# weight = weight.float()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()#weight = weight)\n",
        "params = list(net.parameters()) # parameters are initialized based on layers in net\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01, momentum=0.9) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ550X1Yo9Fe",
        "colab_type": "code",
        "outputId": "f94dd938-2850-45f8-fe18-6555e71ea7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " # loading network\n",
        "# net = TheModelClass(*args, **kwargs)\n",
        "# optimizer = optim.SGD(net.parameters(), lr = 0.002, momentum = 0.9) \n",
        "\n",
        "# checkpoint = torch.load('/content/sppe1%79net.tar')\n",
        "# net.load_state_dict(checkpoint['net_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# # epoch = 'epoch'\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# net.eval()\n",
        "\n",
        "#%% Train the network \n",
        "trainloss = []\n",
        "trainacc = []\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "epochs =1\n",
        "for epoch in range(epochs): #trains over dataset #now once twice\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, data in enumerate(trainloader, 0): \n",
        "      inputs ,labels = data #get inputs\n",
        "      # print(inputs)\n",
        "      # inputs = torch.FloatTensor(inputs)\n",
        "      optimizer.zero_grad() #zero prarameter gradients\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward() # accumulates gradient\n",
        "      optimizer.step() # performs parameter update\n",
        "      \n",
        "      #print statistics\n",
        "      # running_loss += loss.item()\n",
        "      # if i % 5 == 4: #print every 5 mini batches\n",
        "      #   print('[%d, %5d] loss:%3f'% (epoch +1,i+1, running_loss/5))\n",
        "      #   running_loss = 0.0\n",
        "  \n",
        "  # adding accuracy here so it can be plotted with loss against epoch\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      print('actual ',labels)\n",
        "      print('prediction',predicted)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  print('Accuracy of the network on the 100(0) training images: %d %%' % (\n",
        "      100 * correct / total))\n",
        "  trainacc.append(100 * correct / total)\n",
        "  trainloss.append(running_loss/len(trainloader))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# save model\n",
        "# PATH = './net.pth'\n",
        "# torch.save(net.state_dict(), PATH)\n",
        "# # load network\n",
        "# net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad(): # sets all requires_grad flag to false\n",
        "#     for data in testloader:\n",
        "#         images, labels = data\n",
        "#         outputs = net(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print('Accuracy of the network on the 100(0) test images: %d %%' % (\n",
        "#     100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 7])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 0, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 7, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 6])\n",
            "prediction tensor([2, 7, 7, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 6, 2])\n",
            "prediction tensor([7, 7, 0, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 1, 3, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 1, 7, 2])\n",
            "prediction tensor([3, 3, 1, 3])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 6, 2, 2])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 3, 7, 6])\n",
            "prediction tensor([1, 2, 1, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 7, 2])\n",
            "prediction tensor([2, 2, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 6, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 5, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 0, 4, 6])\n",
            "prediction tensor([6, 6, 5, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 0, 7, 6])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 3, 6])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 2, 7])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 7])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 0, 7])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 3])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 6])\n",
            "prediction tensor([1, 1, 1, 1])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 2])\n",
            "prediction tensor([6, 1, 4, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 7])\n",
            "prediction tensor([6, 6, 6, 4])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 7])\n",
            "prediction tensor([6, 6, 6, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 2, 7])\n",
            "prediction tensor([6, 6, 6, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 7])\n",
            "prediction tensor([7, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 2, 6])\n",
            "prediction tensor([6, 6, 6, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 0, 1])\n",
            "prediction tensor([6, 6, 6, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 7, 7])\n",
            "prediction tensor([7, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 6, 6])\n",
            "prediction tensor([2, 7, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 1, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 0, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 0, 6, 5])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 7])\n",
            "prediction tensor([6, 6, 7, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 2, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 7, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 6])\n",
            "prediction tensor([7, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 0, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 1, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 3, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 1, 6, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 4, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 1])\n",
            "prediction tensor([2, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 6, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 4, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 2])\n",
            "prediction tensor([6, 7, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 6])\n",
            "prediction tensor([6, 4, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 6, 4])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 4, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 7, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 3, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 3, 2, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 0, 2, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 7, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 7, 6, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 1, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 0, 7, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 6, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 7, 2, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 0, 3])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 7, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 1])\n",
            "prediction tensor([2, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 0, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 0, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 5, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 4, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 7, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 3])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 2, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 1])\n",
            "prediction tensor([7, 7, 7, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 1, 6, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 2, 4])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 3, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 3, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 6, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 3, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 0, 7, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 1, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 1, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 4, 1, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 3, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 0, 5, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 4, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 7, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 3, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 1, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 4, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 4])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 4, 7, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 1, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 5, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 3, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 4, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 4, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 0, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 7, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 1])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 6, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 1])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 0, 0, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 6, 7, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 3, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 3])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 6, 6, 3])\n",
            "prediction tensor([7, 2, 7, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 0, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 7, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 3, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 1, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 1, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 6, 4])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 1, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 3])\n",
            "prediction tensor([6, 2, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 2])\n",
            "prediction tensor([2, 6, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 7, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 2, 4])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 7, 0, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 5, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 1, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 5, 1, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 0, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 7, 5, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 5, 2, 0])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 4, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 3, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 2])\n",
            "prediction tensor([6, 6, 6, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 0, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 0, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 5, 0, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 5, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 0, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 0, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 1, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 0, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 7, 1, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 1, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 3, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 2])\n",
            "prediction tensor([7, 6, 7, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 2, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 1, 1, 2])\n",
            "prediction tensor([2, 7, 2, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 3, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 2, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 0, 4, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 3, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 0, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 6, 6, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 3, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 6, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 5, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 0, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 3, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 1, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 6, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 5, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 4, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 3, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 6, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 0, 6, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 1, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 6, 1])\n",
            "prediction tensor([6, 6, 6, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 0, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 6, 6, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 5, 5])\n",
            "prediction tensor([2, 6, 2, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 7, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 0, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 7, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 4, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 7, 6])\n",
            "prediction tensor([6, 6, 6, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 1])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 1, 2, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 0, 5])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 2, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 1])\n",
            "prediction tensor([6, 2, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 7])\n",
            "prediction tensor([6, 6, 2, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 3, 6, 7])\n",
            "prediction tensor([2, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 7, 6, 5])\n",
            "prediction tensor([6, 2, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 4, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 5, 4])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 1, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 3, 3, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 4, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 6, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 3, 2, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 1])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 6, 2, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 4, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 7])\n",
            "prediction tensor([2, 2, 6, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 6, 2, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 7, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 4, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 5, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 6, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 6, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 6, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 6, 3])\n",
            "prediction tensor([2, 6, 2, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 7, 4])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 1, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 1, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 4, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 5, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 3, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 0])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 0, 7, 5])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 5, 7, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 3, 2, 2])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 3, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 7])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 4])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 1, 6])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 1, 3])\n",
            "prediction tensor([6, 6, 6, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 1, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 4, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 6, 4])\n",
            "prediction tensor([2, 7, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 6, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 6, 4, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 5, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 3, 6, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 6, 4, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 4, 6, 3])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 7, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 5, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 6, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 2, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 5])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 4, 3])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 0, 1])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 3, 7, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 2, 4, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 3, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 3, 1])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 6, 4, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 7, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 2, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 2, 2, 0])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 4, 5, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 6, 2])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 1, 6])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 5, 7])\n",
            "prediction tensor([7, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 2])\n",
            "prediction tensor([2, 7, 7, 7])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 1, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 7, 5, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 2, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 1, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 5, 5, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 2, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 7, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 1, 7, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 6, 7, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 6, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 6, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([1, 2, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 3, 1, 6])\n",
            "prediction tensor([6, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 2, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 2, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([0, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 1, 4, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 4])\n",
            "prediction tensor([2, 2, 0, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 7, 2, 1])\n",
            "prediction tensor([2, 2, 6, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 6, 7, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 2, 6])\n",
            "prediction tensor([2, 2, 2, 6])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([4, 1, 7, 7])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([5, 2, 7, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 3, 6])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([7, 7, 6, 1])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 2, 6, 2])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([2, 2, 1, 0])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([3, 7, 6, 3])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n",
            "actual  tensor([6, 2, 7, 5])\n",
            "prediction tensor([2, 2, 2, 2])\n",
            "torch.Size([4, 3, 200, 200])\n",
            "torch.Size([4, 16, 196, 196])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6ff0d143e513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# accumulates gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# performs parameter update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "time: 10min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wAK50A2jb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr = 0.002, momentum = 0.9) \n",
        "\n",
        "checkpoint = torch.load('/content/sppnet78.tar')\n",
        "net.load_state_dict(checkpoint['net_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = 'epoch'\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "net.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mPy8X70_bPNw",
        "colab": {}
      },
      "source": [
        "valloss = []\n",
        "valacc = []\n",
        "actual = []\n",
        "pred = []\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = torch.zeros(len(classes), len(classes))\n",
        "for epoch in range(1):\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad(): # sets all requires_grad flag to false\n",
        "    for data in valloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels) #added to compute validation loss\n",
        "        running_loss += loss.item()\n",
        "      \n",
        "        _, predicted = torch.max(outputs.data, 1) # \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        actual.append(labels)\n",
        "        pred.append(predicted)\n",
        "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "  print('Accuracy of the network on the 100(0) validation images: %d %%' % (\n",
        "      100 * correct / total))\n",
        "  valacc.append(100 * correct / total)\n",
        "  valloss.append(running_loss/len(trainloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GwLclGngfIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(labels) # just one batch?\n",
        "# print(outputs)\n",
        "# print(total)\n",
        "# print(correct)\n",
        "# print(predicted)#.size())\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import plot_confusion_matrix\n",
        "actualnp = []\n",
        "prednp = []\n",
        "for i in range(len(actual)):\n",
        "  a=actual[i].tolist()\n",
        "  p=pred[i].tolist()\n",
        "  for j in range(len(a)):\n",
        "    actualnp.append(a[j])\n",
        "    prednp.append(p[j])\n",
        "\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title ='Confusion matrix, without normalization'\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "    \n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "print(actualnp)\n",
        "print(prednp)\n",
        "actualnp = np.array(actualnp)\n",
        "prednp = np.array(prednp)\n",
        "plot_confusion_matrix(actualnp,prednp,np.array([0,1,2,3,4,5,6,7]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9VrPjpJJt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(actual)\n",
        "print(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WUPLeXV3CeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({\n",
        "            # 'epoch': epochs,\n",
        "            'net_state_dict': net.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, '/content/Correctedlabels1e39%net.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6thzisNmXQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# y = [i for i in range(1,epochs+1)]\n",
        "\n",
        "# plt.plot(y, trainloss, y, valloss)\n",
        "# plt.show\n",
        "# plt.savefig('losses.png')\n",
        "# print(trainloss)\n",
        "# print(trainacc)\n",
        "print(valloss)\n",
        "print(valacc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjilwtV1JvI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epo = [i for i in range(4)]\n",
        "# trainloss=trainloss.tolist()\n",
        "# trainacc=trainacc.tolist()\n",
        "# valloss=valloss.tolist()\n",
        "# valacc=valacc.tolist()\n",
        "\n",
        "arrcsv = [['Epochs']+epo, ['Training Loss'] + trainloss,['Training Accuracy']+ trainacc,['Validation Loss']+ valloss, ['Validation Accuracy']+ valacc]\n",
        "print(arrcsv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3fR_KV7FjoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "arrcsv = pd.DataFrame(arrcsv).to_csv('prediction.csv')\n",
        "\n",
        "#make array\n",
        "\n",
        "# arrcsv = torch.FloatTensor(arrcsv)\n",
        "# # access Variable's tensor, copy back to CPU, convert to numpy\n",
        "# arr = arrcsv.data.cpu().numpy()\n",
        "# # type(outputs)\n",
        "# # write CSV\n",
        "# np.savetxt('output.csv', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}